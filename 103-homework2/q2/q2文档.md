# 特征提取

## 变量

```python
    pluno_to_bndno = {}
    pluno_to_sequence = {}
    bndno_to_sequence = {}
    category1_to_sequence = {}
    category2_to_sequence = {}
    category3_to_sequence = {}
    category4_to_sequence = {}
```

以上几个变量通过读取源数据和第一问生成的数据得到。

```
    pluno_to_frequency = {}
    bndno_to_frequency = {}
    category1_to_frequency = {}
    category2_to_frequency = {}
    category3_to_frequency = {}
    category4_to_frequency = {}
```

通过离散值的sequence变量，计算得到的frequency数据。对于离散值，我们采用frequency_encoding的方法进行连续化。这里我们还没有进行标准化。标准化的工作会留到最后一步执行。

```python
    x_names = ['pluno', 'category_1', 'category_2',
               'category_3', 'category_4', 'bndno']
    x_to_sequence = [pluno_to_sequence,category1_to_sequence,category2_to_sequence,category3_to_sequence,category4_to_sequence,bndno_to_sequence]
    x_to_frequency = [pluno_to_frequency, category1_to_frequency, category2_to_frequency,category3_to_frequency, category4_to_frequency,bndno_to_frequency]
    data_recipes = [[0],
                    [0,3],
                    [0,1,2,3],
                    [0,1,2,3,4,5]]
```

这几个变量都是为了批量计算而设置的。引入x_names和x_to_sequence，是为了批量的从上一问生成的文件中读入数据。通过x_to_sequence和x_to_frequency一起，批量的计算零散值的频率信息。最后data_recipes控制有多少种生成特征的方式，每一种方式都有哪几部分特征所构成。

## 函数

### load_data

首先打开之前生成的_to_day_sequence.csv文件，读取内容。

之后打开源文件，读入商品编号和品牌编号的对应信息。

### update_frequency

频率的计算逻辑是，读入每一个sequence元素，每个key对应的value做求和处理，最后除以所有key的求和value，使得frequency变量values的数值的和为1。

### get_feature_set_1

计算I类特征。

其中pluno、bndno、category1、category2、category3、category4六个字段的离散值会用frequency的连续值代替。

是否为工作日用0和1表示，1代表是工作日。

日期用距离初始日期2016/2/1的距离日计算，单位为整数。

past_week1表示计算当前日前一周的quantity数据。同理past_week2表示计算当前日前第二周的quantity数据。以此类推。

之后的特征计算大同小异。get_average_max_min函数被引入，在IV、V、VI类特征中计算平均值，最大值和最小值。

### get_data_recipe

输入pluno, day_offset, recipe_index三个变量，返回使用对应的recipe(菜谱，这里指生成特征的组成部分)，对应商品编号和日期下的特征数据。会调用一系列get_feature_set函数。

### output_feature

输出特征。调用get_data_recipe函数，在/Data/feature/文件夹中，输出1.csv到4.csv四个文件，来按照格式输出数据。每一行的样例如下。

```
22008019,28,0.0005467515096023429,0.000546751509602343,0.04404724583591517,0.015322525140446767,0.005288867047573239,0.0022981870614867173,28,1,0.0,0.0,0.936,0.0,2.279,1.42,0.854
```

前两个字段是产品编号pluno和日期day_offset，之后的字段是所有的特征信息。

## 运行结果

执行data_producer.py，可以看到如下信息。

```
已完成数据加载。
已完成零散特征频率计算。
开始输出../Data/feature/1.csv文件。
已输出100000行。
已输出200000行。
已输出300000行。
已输出400000行。
已输出500000行。
已输出600000行。
已输出700000行。
已输出800000行。
完成输出../Data/feature/1.csv文件。
开始输出../Data/feature/2.csv文件。
已输出100000行。
已输出200000行。
已输出300000行。
已输出400000行。
已输出500000行。
已输出600000行。
已输出700000行。
已输出800000行。
完成输出../Data/feature/2.csv文件。
开始输出../Data/feature/3.csv文件。
已输出100000行。
已输出200000行。
已输出300000行。
已输出400000行。
已输出500000行。
已输出600000行。
已输出700000行。
已输出800000行。
完成输出../Data/feature/3.csv文件。
开始输出../Data/feature/4.csv文件。
已输出100000行。
已输出200000行。
已输出300000行。
已输出400000行。
已输出500000行。
已输出600000行。
已输出700000行。
已输出800000行。
完成输出../Data/feature/4.csv文件。
```

在Data/feature文件夹中输出4个csv文件。每个文件均为800k行左右。

因为4个文件特别大(140M，170M，300M，580M)，我们最后的提交可能不会附带这4个文件。