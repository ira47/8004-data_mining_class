# 预训练与调参

在得到了上两步的结果之后，我们使用numpy来读取前80%数据，使用sklearn来训练模型并调参。整个过程的创新点有：将数据划分为train-validate-test三个部分，训练时进行三折检验来调参。同时使用sklearn自带的joblib来保存训练好的模型。代码在model_params_testor.py中。

## 调参代码

### 变量部分

```python
    def svm_kernel_func(self,k):
        return SVR(kernel=k,max_iter=200)
    svm_kernel = [['linear','poly','rbf','sigmoid'],svm_kernel_func,'svm_kernel']
```

首先是这样的训练函数。在我们的项目中，我们制作了7种可以调整的参数，对应3个模型(MLP、随机森林、svm)。以上的例子是其中的一个。可以看到，svm_kernel这个数组包含了三个元素。第一个元素是喂给函数的参数，第二个函数是工厂函数，用来获得定制的实例。第三个元素是它的名字，用于保存模型时的输出。我们将所有类似svm_kernel这样的配置信息，包含在try_list变量中，具体如下。

```python
    try_list = [
        svm_C,
        svm_kernel,
        rf_n_estimators,
        rf_oob_score,
        mlp_hidden_layer_sizes,
        mlp_activation,
        mlp_solver
    ]
```

## 函数部分

### init_data

导入第二步生成的4个feature文件，对数据进行标准化。

准备好切分数据的变量section_to_start和section_to_end 。

### work

主函数，也是train_and_validate函数的入口函数，两个for函数，提供了recipe，以及要计算的模型的信息。

### train_and_validate

这个函数的两个for，主要是负责迭代函数的可能属性，以及三折检验。在函数中获得模型，训练，保存，预测模型，计算误差，保存输出。

## 参数分析

### svm_c

| params | recipe | train loss | validate loss |
| -----: | ------ | ---------- | ------------- |
|    0.1 | 4      | 1.01962    | 1.021244      |
|      1 | 4      | 0.999722   | 1.000729      |
|     10 | 4      | 1.013307   | 1.019981      |
|    100 | 4      | 0.995587   | 1.090466      |

可以看到，C函数的train loss几乎等于validate loss。而当C=100时，出现了约0.1的误差，数据也没有其他三个好，所以排除C=100及以上数据。

| params | recipe | train loss | validate loss |
| ------ | ------ | ---------- | ------------- |
| 0.1    | 1      | 1.020142   | 1.022223      |
| 1      | 1      | 1.000083   | 1.002698      |
| 10     | 1      | 1.018065   | 1.023536      |
| 0.1    | 2      | 1.019152   | 1.021218      |
| 1      | 2      | 1.002537   | 1.004592      |
| 10     | 2      | 0.995658   | 1.00563       |
| 0.1    | 3      | 1.017194   | 1.018801      |
| 1      | 3      | 0.996677   | 0.997653      |
| 10     | 3      | 1.031796   | 1.039111      |
| 0.1    | 4      | 1.01962    | 1.021244      |
| 1      | 4      | 0.999722   | 1.000729      |
| 10     | 4      | 1.013307   | 1.019981      |

对于C=0.1,1,10三种情况，看四个recipe均是C=1时误差最低。因此最终选择C=1

### svm_kernel

| params  | recipe | train loss | validate loss |
| ------- | ------ | ---------- | ------------- |
| linear  | 4      | 6.31705    | 5.608466      |
| poly    | 4      | 50.68068   | 48.94111      |
| rbf     | 4      | 0.999722   | 1.000729      |
| sigmoid | 4      | 1.246308   | 1.28783       |

明显linear和poly非常不合适。排除。

| params  | recipe | train loss | validate loss |
| ------- | ------ | ---------- | ------------- |
| rbf     | 1      | 1.000083   | 1.002698      |
| sigmoid | 1      | 1.377658   | 1.399492      |
| rbf     | 2      | 1.002537   | 1.004592      |
| sigmoid | 2      | 1.346391   | 1.429027      |
| rbf     | 3      | 0.996677   | 0.997653      |
| sigmoid | 3      | 1.513263   | 1.516841      |
| rbf     | 4      | 0.999722   | 1.000729      |
| sigmoid | 4      | 1.246308   | 1.28783       |

各项数据上，rbf优于sigmond，所以最终选择rbf.

### rf_n_estimates

| params | recipe | train loss | validate loss |
| ------ | ------ | ---------- | ------------- |
| 100    | 4      | 0.38798    | 1.049853      |
| 200    | 3      | 0.374989   | 1.060724      |
| 50     | 4      | 0.376693   | 1.06217       |
| 200    | 4      | 0.374841   | 1.062562      |
| 100    | 3      | 0.383307   | 1.071705      |
| 200    | 2      | 0.376803   | 1.089619      |
| 50     | 3      | 0.375077   | 1.08965       |
| 10     | 4      | 0.484502   | 1.094093      |
| 50     | 1      | 0.371256   | 1.100648      |
| 10     | 3      | 0.401999   | 1.104987      |
| 200    | 1      | 0.376092   | 1.105128      |
| 50     | 2      | 0.38397    | 1.106304      |
| 10     | 1      | 0.465408   | 1.107163      |
| 100    | 1      | 0.371415   | 1.119894      |
| 100    | 2      | 0.378972   | 1.12978       |
| 10     | 2      | 0.405637   | 1.131937      |

事实上，不管怎么选，rf都有严重的过拟合问题。将validate loss升序排列，可以看出优势是200>100>50>10。最终选择n_estimate=200

### rf_oob_score

| params | recipe | train loss | validate loss |
| ------ | ------ | ---------- | ------------- |
| TRUE   | 3      | 0.43631    | 1.059245      |
| FALSE  | 2      | 0.417534   | 1.06041       |
| TRUE   | 4      | 0.424474   | 1.07334       |
| FALSE  | 3      | 0.396297   | 1.117649      |
| TRUE   | 1      | 0.416161   | 1.144295      |
| FALSE  | 4      | 0.424928   | 1.175893      |
| FALSE  | 1      | 0.43163    | 1.186097      |
| TRUE   | 2      | 0.414214   | 1.273183      |

大体上看还是值为TRUE的结果更好一些。选择oob_score为TRUE

### mlp_hidden_layer_sizes

| params | recipe | train loss | validate loss |
| ------ | ------ | ---------- | ------------- |
| 5      | 1      | 0.8502     | 0.980198      |
| 10     | 1      | 0.824453   | 0.982593      |
| 20     | 1      | 0.770493   | 1.023275      |
| 10     | 2      | 0.754561   | 1.025791      |
| 5      | 2      | 0.788326   | 1.029006      |
| 5      | 4      | 0.771326   | 1.029844      |
| 5      | 3      | 0.75558    | 1.042709      |
| 10     | 3      | 0.712132   | 1.07454       |
| 30     | 1      | 0.734657   | 1.091231      |
| 40     | 1      | 0.706954   | 1.116944      |
| 10     | 4      | 0.67673    | 1.121564      |
| 20     | 2      | 0.604456   | 1.132459      |
| 20     | 3      | 0.603004   | 1.155826      |
| 30     | 2      | 0.558487   | 1.160602      |
| 20     | 4      | 0.60948    | 1.189954      |
| 40     | 2      | 0.491125   | 1.225898      |
| 30     | 4      | 0.474828   | 1.244739      |
| 30     | 3      | 0.531817   | 1.25499       |
| 40     | 4      | 0.466723   | 1.277331      |
| 40     | 3      | 0.46665    | 1.296373      |

这里我们只考虑了一层神经网络，奇妙的是，似乎让神经元数=5是比较合适的选择。

### mlp_activation

| params   | recipe | train loss | validate loss |
| -------- | ------ | ---------- | ------------- |
| identity | 1      | 0.887743   | 0.953506      |
| identity | 3      | 0.884624   | 0.954088      |
| identity | 4      | 0.887436   | 0.956683      |
| identity | 2      | 0.881928   | 0.963626      |
| logistic | 3      | 0.816141   | 1.021531      |
| logistic | 2      | 0.842652   | 1.032033      |
| logistic | 4      | 0.808085   | 1.053433      |
| logistic | 1      | 0.859437   | 1.059395      |
| tanh     | 1      | 0.792837   | 1.080316      |
| tanh     | 4      | 0.755688   | 1.136814      |
| tanh     | 3      | 0.701497   | 1.156648      |
| tanh     | 2      | 0.730659   | 1.169881      |
| relu     | 2      | 0.451741   | 1.182856      |
| relu     | 1      | 0.620906   | 1.193468      |
| relu     | 3      | 0.394061   | 1.310487      |
| relu     | 4      | 0.323449   | 1.463727      |

结果是如此的清晰，表明identity是唯一的选择。

### mlp_solver

| params | recipe | train loss | validate loss |
| ------ | ------ | ---------- | ------------- |
| adam   | 1      | 0.678355   | 1.116451      |
| adam   | 2      | 0.419456   | 1.256641      |
| adam   | 3      | 0.424058   | 1.288456      |
| adam   | 4      | 0.320184   | 1.367387      |
| lbfgs  | 1      | 0.332112   | 1.464528      |
| lbfgs  | 4      | 0.204785   | 1.534889      |
| lbfgs  | 3      | 0.199095   | 1.539798      |
| lbfgs  | 2      | 0.216398   | 1.61629       |

结果同样清晰。选择adam。

# 正式训练与测试

根据刚才的分析，我们可以得到三个模型的配置如下。

```python
svm_model = SVR(C=1,kernel='rbf',max_iter=200)
rf_model = RandomForestRegressor(n_estimators=200,oob_score=True,n_jobs=-1)
mlp_model = MLPRegressor(hidden_layer_sizes=5,activation='identity',solver='adam',max_iter=200)
```

编写train_and_test.py来训练和测试最终的数据。代码的逻辑和model_params_testor.py一致。

## 最终结果

| 算法 | recipe   | 1     | 2     | 3      | 4      | 平均   |
| ---- | -------- | ----- | ----- | ------ | ------ | ------ |
| SVM  | 消耗时间 | 2.63  | 3.60  | 6.72   | 11.14  | 6.03   |
|      | 训练误差 | 1.033 | 1.030 | 1.013  | 1.032  | 1.027  |
|      | 测试误差 | 1.027 | 1.028 | 1.012  | 1.030  | 1.024  |
| RF   | 消耗时间 | 40.20 | 58.37 | 231.11 | 484.97 | 143.16 |
|      | 训练误差 | 0.369 | 0.361 | 0.385  | 0.376  | 0.373  |
|      | 测试误差 | 0.864 | 0.844 | 0.842  | 0.839  | 0.847  |
| MLP  | 消耗时间 | 4.45  | 6.65  | 6.31   | 7.44   | 6.21   |
|      | 训练误差 | 0.897 | 0.893 | 0.895  | 0.895  | 0.895  |
|      | 测试误差 | 0.843 | 0.857 | 0.853  | 0.851  | 0.851  |

从结果上看，RF>MLP>SVM。但是由于RF的n_estimate很大，在计算了很多的同时没有避免自身过拟合的问题。而MLP算法耗时短，成果较好。因此我们认为，MLP是最适合该数据的模型。